"""
æ•¸æ“šåˆ†å‰²å·¥å…·ï¼šå¾å®Œæ•´çš„ CSV æ•¸æ“šä¸­åˆ†å‰²å‡ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†
æ”¯æŒå››ç¨®æ•¸æ“šé¡å‹ï¼šè‚¡ç¥¨æ•¸æ“šã€æŠ€è¡“æŒ‡æ¨™ã€åŸºæœ¬é¢æ•¸æ“šã€å°é½ŠåŸºæœ¬é¢æ•¸æ“š
"""

import os
import pandas as pd
from datetime import datetime
from typing import Dict, Tuple, Optional, List
import yaml

class ComprehensiveDataSplitter:
    """
    ç¶œåˆæ•¸æ“šåˆ†å‰²å·¥å…·
    åŒæ™‚åˆ†å‰²è‚¡ç¥¨æ•¸æ“šã€æŠ€è¡“æŒ‡æ¨™ã€åŸºæœ¬é¢æ•¸æ“šå’Œå°é½Šçš„åŸºæœ¬é¢æ•¸æ“š
    """
    
    def __init__(self, 
                 stock_data_dir: str = 'data/stock_data',
                 indicators_dir: str = 'data/indicators',
                 fundamentals_dir: str = 'data/fundamentals',
                 fundamentals_daily_dir: str = 'data/fundamentals/daily_aligned',
                 output_base_dir: str = 'data'):
        """
        åˆå§‹åŒ–ç¶œåˆæ•¸æ“šåˆ†å‰²å™¨
        
        :param stock_data_dir: è‚¡ç¥¨æ•¸æ“šç›®éŒ„
        :param indicators_dir: æŠ€è¡“æŒ‡æ¨™ç›®éŒ„
        :param fundamentals_dir: åŸºæœ¬é¢æ•¸æ“šç›®éŒ„
        :param fundamentals_daily_dir: å°é½ŠåŸºæœ¬é¢æ•¸æ“šç›®éŒ„
        :param output_base_dir: è¼¸å‡ºåŸºç¤ç›®éŒ„
        """
        self.stock_data_dir = stock_data_dir
        self.indicators_dir = indicators_dir
        self.fundamentals_dir = fundamentals_dir
        self.fundamentals_daily_dir = fundamentals_daily_dir
        self.output_base_dir = output_base_dir
        
        # ç‚ºå››ç¨®æ•¸æ“šé¡å‹å‰µå»ºè¼¸å‡ºç›®éŒ„
        self.stock_output_dir = os.path.join(output_base_dir, 'stock_data')
        self.indicators_output_dir = os.path.join(output_base_dir, 'indicators')
        self.fundamentals_output_dir = os.path.join(output_base_dir, 'fundamentals')
        self.fundamentals_daily_output_dir = os.path.join(output_base_dir, 'fundamentals', 'daily_aligned')
        
        for dir_path in [self.stock_output_dir, self.indicators_output_dir, 
                        self.fundamentals_output_dir, self.fundamentals_daily_output_dir]:
            os.makedirs(dir_path, exist_ok=True)
    
    def _find_source_file(self, ticker: str, directory: str, suffix: str) -> Optional[str]:
        """
        åœ¨ç›®éŒ„ä¸­å°‹æ‰¾ç‰¹å®šè‚¡ç¥¨çš„æºæ–‡ä»¶
        
        :param ticker: è‚¡ç¥¨ä»£ç¢¼
        :param directory: æœç´¢ç›®éŒ„
        :param suffix: æ–‡ä»¶å¾Œç¶´ï¼ˆå¦‚ '_2010-01-01_2023-03-01.csv' æˆ– '_indicators.csv'ï¼‰
        :return: å®Œæ•´æ–‡ä»¶è·¯å¾‘æˆ– None
        """
        # å„ªå…ˆå°‹æ‰¾å®Œæ•´æ—¥æœŸç¯„åœçš„æ–‡ä»¶
        priority_patterns = [
            f"{ticker}_2010-01-01_2023-03-01.csv",
            f"{ticker}_2010-01-01_2023-03-01.csv",
        ]
        
        for pattern in priority_patterns:
            full_path = os.path.join(directory, pattern)
            if os.path.exists(full_path):
                return full_path
        
        # å…¶æ¬¡ï¼Œå°‹æ‰¾åŒ¹é…å¾Œç¶´çš„æ–‡ä»¶
        for file in os.listdir(directory):
            if file.startswith(ticker) and file.endswith(suffix):
                return os.path.join(directory, file)
        
        return None
    
    def split_stock_data(self, 
                        ticker: str, 
                        train_start: str, 
                        train_end: str,
                        test_start: str,
                        test_end: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """åˆ†å‰²è‚¡ç¥¨ OHLCV æ•¸æ“š"""
        stock_file = self._find_source_file(ticker, self.stock_data_dir, '_2010-01-01_2023-03-01.csv')
        
        if not stock_file:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker} çš„åŸå§‹æ•¸æ“šæ–‡ä»¶")
        
        train_start_dt = pd.to_datetime(train_start)
        train_end_dt = pd.to_datetime(train_end)
        test_start_dt = pd.to_datetime(test_start)
        test_end_dt = pd.to_datetime(test_end)
        
        data = pd.read_csv(stock_file)
        data['date'] = pd.to_datetime(data['date'])
        
        train_data = data[(data['date'] >= train_start_dt) & (data['date'] <= train_end_dt)].copy()
        test_data = data[(data['date'] >= test_start_dt) & (data['date'] <= test_end_dt)].copy()
        
        return train_data, test_data
    
    def split_indicators_data(self, 
                             ticker: str, 
                             train_start: str, 
                             train_end: str,
                             test_start: str,
                             test_end: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """åˆ†å‰²æŠ€è¡“æŒ‡æ¨™æ•¸æ“š"""
        indicators_file = self._find_source_file(ticker, self.indicators_dir, '_indicators.csv')
        
        if not indicators_file:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker} çš„æŠ€è¡“æŒ‡æ¨™æ–‡ä»¶")
        
        train_start_dt = pd.to_datetime(train_start)
        train_end_dt = pd.to_datetime(train_end)
        test_start_dt = pd.to_datetime(test_start)
        test_end_dt = pd.to_datetime(test_end)
        
        data = pd.read_csv(indicators_file)
        data['date'] = pd.to_datetime(data['date'])
        
        train_data = data[(data['date'] >= train_start_dt) & (data['date'] <= train_end_dt)].copy()
        test_data = data[(data['date'] >= test_start_dt) & (data['date'] <= test_end_dt)].copy()
        
        return train_data, test_data
    
    def split_fundamentals_data(self, 
                               ticker: str, 
                               train_start: str, 
                               train_end: str,
                               test_start: str,
                               test_end: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """åˆ†å‰²åŸºæœ¬é¢æ•¸æ“šï¼ˆæŒ‰å­£åº¦ï¼‰"""
        fundamentals_file = self._find_source_file(ticker, self.fundamentals_dir, '_fundamentals.csv')
        
        if not fundamentals_file:
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker} çš„åŸºæœ¬é¢æ•¸æ“šæ–‡ä»¶")
        
        train_start_dt = pd.to_datetime(train_start)
        train_end_dt = pd.to_datetime(train_end)
        test_start_dt = pd.to_datetime(test_start)
        test_end_dt = pd.to_datetime(test_end)
        
        data = pd.read_csv(fundamentals_file)
        
        # åŸºæœ¬é¢æ•¸æ“šä½¿ç”¨ fiscalDateEnding æˆ– date ä½œç‚ºæ—¥æœŸåˆ—
        date_col = None
        for col in ['fiscalDateEnding', 'date', 'Date']:
            if col in data.columns:
                date_col = col
                break
        
        if not date_col:
            return data.copy(), data.copy()
        
        data[date_col] = pd.to_datetime(data[date_col])
        
        train_data = data[(data[date_col] >= train_start_dt) & (data[date_col] <= train_end_dt)].copy()
        test_data = data[(data[date_col] >= test_start_dt) & (data[date_col] <= test_end_dt)].copy()
        
        return train_data, test_data
    
    def split_fundamentals_daily_data(self, 
                                     ticker: str, 
                                     train_start: str, 
                                     train_end: str,
                                     test_start: str,
                                     test_end: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        åˆ†å‰²å°é½Šçš„æ—¥åº¦åŸºæœ¬é¢æ•¸æ“š
        ï¼ˆå·²èˆ‡äº¤æ˜“æ—¥å°é½Šçš„åŸºæœ¬é¢æ•¸æ“šï¼‰
        """
        # å°‹æ‰¾å°é½Šçš„åŸºæœ¬é¢æ•¸æ“šæ–‡ä»¶
        daily_file = os.path.join(self.fundamentals_daily_dir, f"{ticker}_fundamentals_daily.csv")
        
        if not os.path.exists(daily_file):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è‚¡ç¥¨ {ticker} çš„å°é½ŠåŸºæœ¬é¢æ•¸æ“šæ–‡ä»¶: {daily_file}")
        
        train_start_dt = pd.to_datetime(train_start)
        train_end_dt = pd.to_datetime(train_end)
        test_start_dt = pd.to_datetime(test_start)
        test_end_dt = pd.to_datetime(test_end)
        
        # è¼‰å…¥æ•¸æ“š
        data = pd.read_csv(daily_file)
        data['date'] = pd.to_datetime(data['date'])
        
        # åˆ†å‰²è¨“ç·´é›†å’Œæ¸¬è©¦é›†
        train_data = data[(data['date'] >= train_start_dt) & (data['date'] <= train_end_dt)].copy()
        test_data = data[(data['date'] >= test_start_dt) & (data['date'] <= test_end_dt)].copy()
        
        return train_data, test_data
    
    def split_ticker(self, 
                    ticker: str, 
                    train_start: str, 
                    train_end: str,
                    test_start: str,
                    test_end: str) -> Dict[str, Dict]:
        """
        ç‚ºå–®å€‹è‚¡ç¥¨åˆ†å‰²å››ç¨®æ•¸æ“šé¡å‹
        
        :return: åŒ…å«åˆ†å‰²çµæœå’Œæ–‡ä»¶è·¯å¾‘çš„å­—å…¸
        """
        results = {'ticker': ticker, 'data_types': {}}
        
        # 1. åˆ†å‰²è‚¡ç¥¨æ•¸æ“š
        try:
            train_stock, test_stock = self.split_stock_data(
                ticker, train_start, train_end, test_start, test_end
            )
            
            train_file = os.path.join(self.stock_output_dir, f"{ticker}_{train_start}_{train_end}.csv")
            test_file = os.path.join(self.stock_output_dir, f"{ticker}_{test_start}_{test_end}.csv")
            
            train_stock.to_csv(train_file, index=False)
            test_stock.to_csv(test_file, index=False)
            
            results['data_types']['stock'] = {
                'status': 'success',
                'train': {'file': train_file, 'rows': len(train_stock)},
                'test': {'file': test_file, 'rows': len(test_stock)}
            }
        except Exception as e:
            results['data_types']['stock'] = {'status': 'error', 'message': str(e)}
        
        # 2. åˆ†å‰²æŠ€è¡“æŒ‡æ¨™æ•¸æ“š
        try:
            train_ind, test_ind = self.split_indicators_data(
                ticker, train_start, train_end, test_start, test_end
            )
            
            train_file = os.path.join(self.indicators_output_dir, f"{ticker}_{train_start}_{train_end}.csv")
            test_file = os.path.join(self.indicators_output_dir, f"{ticker}_{test_start}_{test_end}.csv")
            
            train_ind.to_csv(train_file, index=False)
            test_ind.to_csv(test_file, index=False)
            
            results['data_types']['indicators'] = {
                'status': 'success',
                'train': {'file': train_file, 'rows': len(train_ind)},
                'test': {'file': test_file, 'rows': len(test_ind)}
            }
        except Exception as e:
            results['data_types']['indicators'] = {'status': 'error', 'message': str(e)}
        
        # 3. åˆ†å‰²åŸºæœ¬é¢æ•¸æ“šï¼ˆå­£åº¦æ•¸æ“šï¼‰
        try:
            train_fund, test_fund = self.split_fundamentals_data(
                ticker, train_start, train_end, test_start, test_end
            )
            
            train_file = os.path.join(self.fundamentals_output_dir, f"{ticker}_{train_start}_{train_end}.csv")
            test_file = os.path.join(self.fundamentals_output_dir, f"{ticker}_{test_start}_{test_end}.csv")
            
            train_fund.to_csv(train_file, index=False)
            test_fund.to_csv(test_file, index=False)
            
            results['data_types']['fundamentals'] = {
                'status': 'success',
                'train': {'file': train_file, 'rows': len(train_fund)},
                'test': {'file': test_file, 'rows': len(test_fund)}
            }
        except Exception as e:
            results['data_types']['fundamentals'] = {'status': 'error', 'message': str(e)}
        
        # 4. åˆ†å‰²å°é½Šçš„åŸºæœ¬é¢æ•¸æ“šï¼ˆæ—¥åº¦æ•¸æ“šï¼‰
        try:
            train_daily, test_daily = self.split_fundamentals_daily_data(
                ticker, train_start, train_end, test_start, test_end
            )
            
            train_file = os.path.join(self.fundamentals_daily_output_dir, f"{ticker}_{train_start}_{train_end}.csv")
            test_file = os.path.join(self.fundamentals_daily_output_dir, f"{ticker}_{test_start}_{test_end}.csv")
            
            train_daily.to_csv(train_file, index=False)
            test_daily.to_csv(test_file, index=False)
            
            results['data_types']['fundamentals_daily'] = {
                'status': 'success',
                'train': {'file': train_file, 'rows': len(train_daily)},
                'test': {'file': test_file, 'rows': len(test_daily)}
            }
        except Exception as e:
            results['data_types']['fundamentals_daily'] = {'status': 'error', 'message': str(e)}
        
        return results
    
    def split_all_tickers(self, 
                         tickers: List[str], 
                         train_start: str, 
                         train_end: str,
                         test_start: str,
                         test_end: str) -> Dict:
        """
        åˆ†å‰²æ‰€æœ‰è‚¡ç¥¨çš„å››ç¨®æ•¸æ“šé¡å‹
        
        :param tickers: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        :param train_start: è¨“ç·´é–‹å§‹æ—¥æœŸ
        :param train_end: è¨“ç·´çµæŸæ—¥æœŸ
        :param test_start: æ¸¬è©¦é–‹å§‹æ—¥æœŸ
        :param test_end: æ¸¬è©¦çµæŸæ—¥æœŸ
        :return: æ‰€æœ‰çµæœçš„å­—å…¸
        """
        print(f"\n{'='*80}")
        print(f"ğŸ”„ é–‹å§‹åˆ†å‰²ç¶œåˆæ•¸æ“šï¼ˆå«å°é½ŠåŸºæœ¬é¢æ•¸æ“šï¼‰")
        print(f"{'='*80}\n")
        
        print(f"è¨“ç·´æœŸé–“: {train_start} è‡³ {train_end}")
        print(f"æ¸¬è©¦æœŸé–“: {test_start} è‡³ {test_end}")
        print(f"è‚¡ç¥¨æ•¸é‡: {len(tickers)}")
        print(f"\nè™•ç†è‚¡ç¥¨:\n")
        
        all_results = {}
        
        for idx, ticker in enumerate(tickers, 1):
            print(f"  [{idx:2d}/{len(tickers)}] {ticker:6s}", end=' | ')
            
            try:
                result = self.split_ticker(ticker, train_start, train_end, test_start, test_end)
                all_results[ticker] = result
                
                # æª¢æŸ¥çµæœ
                successful_types = sum(
                    1 for dt in result['data_types'].values() 
                    if dt.get('status') == 'success'
                )
                print(f"âœ“ {successful_types}/4 æ•¸æ“šé¡å‹æˆåŠŸ")
                
            except Exception as e:
                print(f"âœ— éŒ¯èª¤: {e}")
                all_results[ticker] = {'error': str(e)}
        
        print(f"\n{'='*80}")
        print(f"âœ… åˆ†å‰²å®Œæˆï¼")
        print(f"{'='*80}\n")
        
        return all_results
    
    def split_from_config(self, config_path: str = 'configs/defaults.yaml') -> Dict:
        """
        å¾é…ç½®æ–‡ä»¶ä¸­è®€å–æ—¥æœŸå’Œè‚¡ç¥¨åˆ—è¡¨ï¼Œè‡ªå‹•é€²è¡Œåˆ†å‰²
        
        :param config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
        :return: åˆ†å‰²çµæœå­—å…¸
        """
        print(f"\nğŸ“‹ å¾é…ç½®æ–‡ä»¶è¼‰å…¥: {config_path}\n")
        
        # è¼‰å…¥é…ç½®
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        data_cfg = config['data']
        
        # æå–é…ç½®ä¿¡æ¯
        train_start = data_cfg['train_date_start']
        train_end = data_cfg['train_date_end']
        test_start = data_cfg['test_date_start']
        test_end = data_cfg['test_date_end']
        tickers = data_cfg['ticker_list']
        
        print(f"é…ç½®ä¿¡æ¯:")
        print(f"  è¨“ç·´æœŸé–“: {train_start} è‡³ {train_end}")
        print(f"  æ¸¬è©¦æœŸé–“: {test_start} è‡³ {test_end}")
        print(f"  è‚¡ç¥¨æ•¸é‡: {len(tickers)}\n")
        
        # åŸ·è¡Œåˆ†å‰²
        return self.split_all_tickers(
            tickers, train_start, train_end, test_start, test_end
        )
    
    def print_summary(self, results: Dict):
        """
        æ‰“å°åˆ†å‰²çµæœè©³ç´°æ‘˜è¦
        
        :param results: åˆ†å‰²çµæœå­—å…¸
        """
        print(f"\n{'='*80}")
        print(f"ğŸ“Š åˆ†å‰²çµæœè©³ç´°æ‘˜è¦")
        print(f"{'='*80}\n")
        
        data_types_summary = {
            'stock': {}, 
            'indicators': {}, 
            'fundamentals': {},
            'fundamentals_daily': {}
        }
        
        for ticker, result in results.items():
            if 'error' in result:
                print(f"âŒ {ticker:6s} - éŒ¯èª¤: {result['error']}")
                continue
            
            print(f"âœ… {ticker}")
            
            for data_type, info in result['data_types'].items():
                if info.get('status') == 'success':
                    train_rows = info['train']['rows']
                    test_rows = info['test']['rows']
                    
                    display_name = {
                        'stock': 'è‚¡ç¥¨æ•¸æ“š    ',
                        'indicators': 'æŠ€è¡“æŒ‡æ¨™    ',
                        'fundamentals': 'åŸºæœ¬é¢æ•¸æ“š  ',
                        'fundamentals_daily': 'å°é½ŠåŸºæœ¬é¢  '
                    }.get(data_type, data_type)
                    
                    print(f"    {display_name} | è¨“ç·´: {train_rows:5d} è¡Œ | æ¸¬è©¦: {test_rows:5d} è¡Œ")
                    
                    # ç´¯è¨ˆçµ±è¨ˆ
                    if data_type not in data_types_summary:
                        data_types_summary[data_type] = {}
                    if 'total_train' not in data_types_summary[data_type]:
                        data_types_summary[data_type]['total_train'] = 0
                        data_types_summary[data_type]['total_test'] = 0
                    
                    data_types_summary[data_type]['total_train'] += train_rows
                    data_types_summary[data_type]['total_test'] += test_rows
                else:
                    print(f"    {data_type:15s} | âŒ {info.get('message', 'æœªçŸ¥éŒ¯èª¤')}")
        
        # æ‰“å°ç¸½çµ
        print(f"\n{'-'*80}")
        print(f"ğŸ“ˆ æ•¸æ“šé¡å‹ç¸½çµ:")
        
        data_type_names = {
            'stock': 'è‚¡ç¥¨æ•¸æ“š',
            'indicators': 'æŠ€è¡“æŒ‡æ¨™',
            'fundamentals': 'åŸºæœ¬é¢æ•¸æ“š',
            'fundamentals_daily': 'å°é½ŠåŸºæœ¬é¢'
        }
        
        for data_type in ['stock', 'indicators', 'fundamentals', 'fundamentals_daily']:
            if data_types_summary[data_type]:
                summary = data_types_summary[data_type]
                name = data_type_names.get(data_type, data_type)
                print(f"  {name:12s} | è¨“ç·´ç¸½è¡Œæ•¸: {summary['total_train']:8d} | æ¸¬è©¦ç¸½è¡Œæ•¸: {summary['total_test']:8d}")
        
        print(f"{'='*80}\n")


if __name__ == "__main__":
    # å¾é…ç½®æ–‡ä»¶è‡ªå‹•åˆ†å‰²æ‰€æœ‰è‚¡ç¥¨çš„å››ç¨®æ•¸æ“š
    splitter = ComprehensiveDataSplitter()
    results = splitter.split_from_config('configs/defaults.yaml')
    splitter.print_summary(results)