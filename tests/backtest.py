import numpy as np
import pandas as pd
import torch
from typing import Dict
from datetime import datetime
import json
import os


class BacktestEngine:
    """
    å›æ¸¬å¼•æ“ - è©•ä¼°å¼·åŒ–å­¸ç¿’äº¤æ˜“ç­–ç•¥çš„è¡¨ç¾
    
    åŠŸèƒ½ï¼š
    1. åŠ è¼‰å·²è¨“ç·´çš„æ¨¡å‹
    2. åœ¨æ­·å²æ•¸æ“šä¸Šé‹è¡Œç­–ç•¥
    3. è¨ˆç®—æ€§èƒ½æŒ‡æ¨™ (æ”¶ç›Šç‡ã€Sharpe Ratioã€æœ€å¤§å›æ’¤ç­‰)
    4. ç”Ÿæˆå›æ¸¬å ±å‘Šå’Œå¯è¦–åŒ–
    """
    
    def __init__(self, initial_balance: float = 100000, transaction_cost: float = 0.001):
        """
        åˆå§‹åŒ–å›æ¸¬å¼•æ“
        
        :param initial_balance: åˆå§‹è³‡é‡‘
        :param transaction_cost: äº¤æ˜“æˆæœ¬ï¼ˆç™¾åˆ†æ¯”ï¼‰
        """
        self.initial_balance = initial_balance
        self.transaction_cost = transaction_cost
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # å›æ¸¬çµæœ
        self.results = {
            'daily_values': [],
            'portfolio_values': [],
            'returns': [],
            'actions': [],
            'timestamps': [],
            'trades': []
        }
    
    def load_model(self, path: str) -> object:
        """
        åŠ è¼‰å·²è¨“ç·´çš„æ¨¡å‹
        
        :param path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘
        :return: åŠ è¼‰çš„æ¨¡å‹å¯¦ä¾‹
        """
        print(f"[BacktestEngine] åŠ è¼‰æ¨¡å‹: {path}")
        
        if not os.path.exists(path):
            raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {path}")
        
        try:
            # è¼‰å…¥æª¢æŸ¥é»
            checkpoint = torch.load(path, map_location=self.device)
            
            # â† æª¢æŸ¥æ¨¡å‹é¡å‹ï¼ˆæ ¹æ“šæª¢æŸ¥é»çš„éµä¾†åˆ¤æ–·ï¼‰
            if 'q_network' in checkpoint:
                # DDQN æ¨¡å‹
                algo_type = 'ddqn'
                print(f"  â”œâ”€ æª¢æ¸¬åˆ°æ¼”ç®—æ³•: DDQN")
            elif 'actor' in checkpoint and 'critic' in checkpoint:
                # DDPG æˆ– A2C æ¨¡å‹
                if 'target_actor' in checkpoint:
                    algo_type = 'ddpg'
                    print(f"  â”œâ”€ æª¢æ¸¬åˆ°æ¼”ç®—æ³•: DDPG")
                else:
                    algo_type = 'a2c'
                    print(f"  â”œâ”€ æª¢æ¸¬åˆ°æ¼”ç®—æ³•: A2C")
            else:
                raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹æ ¼å¼: {list(checkpoint.keys())}")
            
            # â† æ ¹æ“šæª¢æŸ¥é»å…§å®¹æ¨æ–·æ¨¡å‹é…ç½®
            # æª¢æŸ¥æ˜¯å¦ä½¿ç”¨æ³¨æ„åŠ›
            has_attention = False
            if algo_type == 'ddqn':
                has_attention = any('attention' in k for k in checkpoint.get('q_network', {}).keys())
            else:
                has_attention = any('attention' in k for k in checkpoint.get('actor', {}).keys())
            
            print(f"  â”œâ”€ ä½¿ç”¨æ³¨æ„åŠ›: {has_attention}")
            print(f"  â””â”€ âœ“ æ¨¡å‹æª¢æ¸¬å®Œæˆ\n")
            
            # â† è¿”å›æª¢æŸ¥é»å’Œæ¨¡å‹é¡å‹ï¼Œè®“èª¿ç”¨è€…æ±ºå®šå¦‚ä½•è™•ç†
            return {
                'checkpoint': checkpoint,
                'algo_type': algo_type,
                'has_attention': has_attention,
            }
        
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {str(e)}")
            raise
    
    def run_backtest(self, env, model, num_episodes: int = 1,
                     deterministic: bool = True) -> dict:
        """
        åŸ·è¡Œå›æ¸¬
        
        :param env: äº¤æ˜“ç’°å¢ƒ
        :param model: å¼·åŒ–å­¸ç¿’æ¨¡å‹å¯¦ä¾‹
        :param num_episodes: å›æ¸¬å›åˆæ•¸
        :param deterministic: æ˜¯å¦ä½¿ç”¨ç¢ºå®šæ€§å‹•ä½œé¸æ“‡
        :return: å›æ¸¬çµæœå­—å…¸
        """
        print(f"[BacktestEngine] é–‹å§‹å›æ¸¬...")
        print(f"  - åˆå§‹è³‡é‡‘: ${self.initial_balance:,.2f}")
        print(f"  - äº¤æ˜“æˆæœ¬: {self.transaction_cost * 100:.2f}%")
        print(f"  - ç’°å¢ƒ: {num_episodes} å›åˆ\n")
        
        results = {
            'episode_returns': [],
            'episode_final_values': [],
            'total_trades': [],
            'winning_trades': [],
            'daily_returns': [],
            'actions_history': [],
        }
        
        for episode in range(num_episodes):
            print(f"[BacktestEngine] å›åˆ {episode + 1}/{num_episodes}")
            
            # é‡ç½®ç’°å¢ƒ
            state = env.reset()
            done = False
            episode_return = 0
            episode_trades = 0
            winning_trades = 0
            
            episode_values = [self.initial_balance]
            episode_actions = []
            
            step = 0
            while not done:
                # é¸æ“‡å‹•ä½œ
                if deterministic:
                    action = model.select_action_deterministic(state)
                else:
                    action = model.select_action(state, noise_scale=0.0)
                
                # åŸ·è¡Œå‹•ä½œ
                next_state, reward, done, info = env.step(action)
                
                # è¨˜éŒ„
                episode_return += reward
                episode_values.append(info.get('portfolio_value', self.initial_balance))
                episode_actions.append(action)
                
                # çµ±è¨ˆäº¤æ˜“
                if 'num_trades' in info:
                    trades = info['num_trades']
                    if trades > episode_trades:
                        episode_trades = trades
                        if reward > 0:
                            winning_trades += 1
                
                state = next_state
                step += 1
                
                if step >= env.max_steps:
                    break
            
            # è¨˜éŒ„çµæœ
            final_value = episode_values[-1]
            total_return = (final_value - self.initial_balance) / self.initial_balance
            
            results['episode_returns'].append(total_return)
            results['episode_final_values'].append(final_value)
            results['total_trades'].append(episode_trades)
            results['winning_trades'].append(winning_trades)
            results['daily_returns'].append(episode_values)
            results['actions_history'].append(episode_actions)
            
            print(f"  â”œâ”€ æœ€çµ‚è³‡é‡‘: ${final_value:,.2f}")
            print(f"  â”œâ”€ å›å ±ç‡: {total_return * 100:.2f}%")
            print(f"  â”œâ”€ äº¤æ˜“æ¬¡æ•¸: {episode_trades}")
            print(f"  â””â”€ å‹ç‡: {winning_trades}/{episode_trades if episode_trades > 0 else 1}\n")
        
        return results
    
    def calculate_metrics(self, results: Dict, risk_free_rate: float = 0.02) -> Dict:
        """
        è¨ˆç®—å›æ¸¬æ€§èƒ½æŒ‡æ¨™
        
        ç‚ºä»€éº¼å¤šå€‹ Episodes èƒ½æä¾›æ›´å¥½çš„æŒ‡æ¨™ï¼š
        - Sharpe Ratio: åŸºæ–¼å¤š Episodes çš„æ¨™æº–å·®è¨ˆç®—ï¼Œæ›´å¯é 
        - Max Drawdown: è€ƒæ…®æ•´å€‹å›æ¸¬æœŸé–“çš„æœ€å¤§æå¤±
        - Win Rate: åŸºæ–¼å¤š Episodes çš„å‹ç‡çµ±è¨ˆ
        - ç©©å®šæ€§: èƒ½è©•ä¼°æ”¶ç›Šçš„ä¸€è‡´æ€§
        """
        print(f"[BacktestEngine] è¨ˆç®—æ€§èƒ½æŒ‡æ¨™...\n")
        
        returns = np.array(results['episode_returns'])
        final_values = np.array(results['episode_final_values'])
        sharpes = np.array(results['episode_sharpe'])
        max_dds = np.array(results['episode_max_drawdown'])
        
        # åŸºæœ¬æŒ‡æ¨™
        total_return = np.mean(returns)
        std_return = np.std(returns)
        min_return = np.min(returns)
        max_return = np.max(returns)
        
        # Sharpe Ratioï¼ˆå¤š Episodes å¹³å‡ï¼‰
        sharpe_ratio = np.mean(sharpes)
        sharpe_std = np.std(sharpes)
        
        # æœ€å¤§å›æ’¤ï¼ˆå¤š Episodes å¹³å‡ï¼‰
        max_drawdown = np.mean(max_dds)
        
        # Calmar Ratio
        calmar_ratio = total_return / abs(max_drawdown) if max_drawdown != 0 else 0
        
        # å‹ç‡
        num_winning = np.sum(returns > 0)
        win_rate = num_winning / len(returns)
        
        # å¹³å‡äº¤æ˜“æ¬¡æ•¸
        avg_trades = np.mean(results['total_trades'])
        avg_winning_trades = np.mean(results['winning_trades'])
        
        # â† æ–°å¢ï¼šç©©å®šæ€§æŒ‡æ¨™
        # å›å ±çš„ä¿‚æ•¸è®Šç•°æ•¸ï¼ˆè¶Šå°è¶Šç©©å®šï¼‰
        cv_return = std_return / abs(total_return) if total_return != 0 else float('inf')
        
        metrics = {
            'total_return': float(total_return),
            'return_std': float(std_return),
            'min_return': float(min_return),
            'max_return': float(max_return),
            'return_cv': float(cv_return),  # â† ç©©å®šæ€§
            'annual_return': float(total_return),
            'volatility': float(std_return),
            'sharpe_ratio': float(sharpe_ratio),
            'sharpe_std': float(sharpe_std),  # â† Sharpe çš„ç©©å®šæ€§
            'max_drawdown': float(max_drawdown),
            'calmar_ratio': float(calmar_ratio),
            'win_rate': float(win_rate),
            'avg_trades': float(avg_trades),
            'avg_winning_trades': float(avg_winning_trades),
            'final_value': float(np.mean(final_values)),
            'num_episodes': len(returns),
        }
        
        return metrics
    
    def print_report(self, metrics: Dict):
        """æ”¹é€²çš„å›æ¸¬å ±å‘Š"""
        print(f"\n{'='*80}")
        print(f"{'å›æ¸¬å ±å‘Š':<40} {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*80}\n")
        
        print(f"ğŸ“Š å›æ¸¬é…ç½®")
        print(f"{'â”€'*80}")
        print(f"  å›åˆæ•¸: {metrics['num_episodes']} (ç‚ºä»€éº¼?: è¨ˆç®—å¯é çš„çµ±è¨ˆæŒ‡æ¨™)")
        
        print(f"\nğŸ“ˆ æ”¶ç›ŠæŒ‡æ¨™")
        print(f"{'â”€'*80}")
        print(f"  å¹³å‡å›å ±ç‡:     {metrics['total_return']*100:>10.2f}%")
        print(f"  æ¨™æº–å·®:        {metrics['return_std']*100:>10.2f}% (æ³¢å‹•ç¨‹åº¦)")
        print(f"  æœ€å°å›å ±:       {metrics['min_return']*100:>10.2f}%")
        print(f"  æœ€å¤§å›å ±:       {metrics['max_return']*100:>10.2f}%")
        print(f"  è®Šç•°ä¿‚æ•¸:       {metrics['return_cv']:>10.2f}x (â†“ è¶Šå°è¶Šç©©å®š)")
        
        print(f"\nğŸ¯ é¢¨éšªèª¿æ•´æŒ‡æ¨™")
        print(f"{'â”€'*80}")
        print(f"  Sharpe æ¯”ç‡:    {metrics['sharpe_ratio']:>10.2f} (å¹³å‡)")
        print(f"  Sharpe ç©©å®šæ€§:  {metrics['sharpe_std']:>10.2f} std (â†“ è¶Šå°è¶Šç©©å®š)")
        print(f"  æœ€å¤§å›æ’¤:       {metrics['max_drawdown']*100:>10.2f}%")
        print(f"  Calmar æ¯”ç‡:    {metrics['calmar_ratio']:>10.2f}")
        
        print(f"\nğŸ¯ äº¤æ˜“æŒ‡æ¨™")
        print(f"{'â”€'*80}")
        print(f"  å‹ç‡:           {metrics['win_rate']*100:>10.2f}%")
        print(f"  å¹³å‡äº¤æ˜“æ¬¡æ•¸:   {metrics['avg_trades']:>10.1f}")
        print(f"  å¹³å‡å‹äº¤æ˜“:     {metrics['avg_winning_trades']:>10.1f}")
        
        print(f"\n{'='*80}\n")
    
    def save_report(self, metrics: Dict, results: Dict, output_path: str = './backtest_report.json'):
        """
        ä¿å­˜å›æ¸¬å ±å‘Š
        
        :param metrics: æ€§èƒ½æŒ‡æ¨™
        :param results: å›æ¸¬çµæœ
        :param output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        report = {
            'timestamp': datetime.now().isoformat(),
            'metrics': metrics,
            'summary': {
                'num_episodes': len(results['episode_returns']),
                'total_trades': int(np.sum(results['total_trades'])),
                'winning_trades': int(np.sum(results['winning_trades'])),
            }
        }
        
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"[BacktestEngine] å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}\n")
    
    def generate_csv_report(self, results: Dict, output_path: str = './backtest_results.csv'):
        """
        ç”Ÿæˆ CSV å›æ¸¬çµæœ
        
        :param results: å›æ¸¬çµæœ
        :param output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        df_data = {
            'Episode': np.arange(1, len(results['episode_returns']) + 1),
            'Final Value': results['episode_final_values'],
            'Return %': np.array(results['episode_returns']) * 100,
            'Num Trades': results['total_trades'],
            'Winning Trades': results['winning_trades'],
        }
        
        df = pd.DataFrame(df_data)
        
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        df.to_csv(output_path, index=False)
        
        print(f"[BacktestEngine] CSV å ±å‘Šå·²ä¿å­˜åˆ°: {output_path}\n")


class BacktestComparator:
    """
    å›æ¸¬æ¯”è¼ƒå™¨ - æ¯”è¼ƒå¤šå€‹æ¨¡å‹çš„æ€§èƒ½
    """
    
    def __init__(self):
        self.backtest_results = {}
    
    def add_result(self, model_name: str, metrics: Dict):
        """
        æ·»åŠ å›æ¸¬çµæœ
        
        :param model_name: æ¨¡å‹åç¨±
        :param metrics: æ€§èƒ½æŒ‡æ¨™
        """
        self.backtest_results[model_name] = metrics
    
    def compare(self) -> pd.DataFrame:
        """
        æ¯”è¼ƒå¤šå€‹æ¨¡å‹
        
        :return: æ¯”è¼ƒçµæœ DataFrame
        """
        df = pd.DataFrame(self.backtest_results).T
        
        # æŒ‰ Sharpe Ratio æ’åº
        df = df.sort_values('sharpe_ratio', ascending=False)
        
        return df
    
    def print_comparison(self):
        """
        æ‰“å°æ¯”è¼ƒçµæœ
        """
        df = self.compare()
        
        print(f"\n{'='*100}")
        print(f"{'æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ':<50}")
        print(f"{'='*100}\n")
        
        print(df.to_string())
        
        print(f"\n{'='*100}\n")
    
    def save_comparison(self, output_path: str = './model_comparison.csv'):
        """
        ä¿å­˜æ¯”è¼ƒçµæœ
        
        :param output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        df = self.compare()
        os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
        df.to_csv(output_path)
        
        print(f"[BacktestComparator] æ¯”è¼ƒçµæœå·²ä¿å­˜åˆ°: {output_path}\n")